{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b48aa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/paper3810/lib/python3.8/site-packages/nnAudio/Spectrogram.py:4: Warning: importing Spectrogram subpackage will be deprecated soon. You should import the feature extractor from the feature subpackage. See actual documentation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Libraries related to PyTorch\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torchaudio \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import WeightedRandomSampler,DataLoader\n",
    "\n",
    "# Libraries related to PyTorch Lightning\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Libraries related to hydra\n",
    "import hydra\n",
    "from hydra.utils import to_absolute_path\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# custom packages\n",
    "from dataset.speechcommands import SPEECHCOMMANDS_12C #for 12 classes KWS task\n",
    "import models as Model \n",
    "\n",
    "from dataloading_util import data_processing\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed9bc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hydra.initialize(\"conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46ab9ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/paper3810/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'KWS_config': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# To set mel trainable, put \"model.spec_args.trainable_mel=True\" into the overrides list\n",
    "# This is equalivant nnAudio.features.mel.MelSpectrogram(trainable_mel=True) at line 50 of models/nnAudio_model.py \n",
    "\n",
    "# To set mel trainable xxx\n",
    "# To both trainable xxx\n",
    "\n",
    "#\n",
    "\n",
    "cfg = hydra.compose(\"KWS_config\", overrides=[\"model.spec_args.trainable_mel=True\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c2a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3789b5b7",
   "metadata": {},
   "source": [
    "# Setting up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87acf225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root': '${data_root}', 'url': 'speech_commands_v0.02', 'folder_in_archive': 'SpeechCommands', 'download': '${download}', 'subset': 'training'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.dataset.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4395a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basename='speech_commands_v0.02.tar.gz'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading training set: 100%|███████████| 84843/84843 [00:28<00:00, 3007.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basename='speech_commands_v0.02.tar.gz'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading validation set: 100%|███████████| 9981/9981 [00:05<00:00, 1791.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basename='speech_commands_test_set_v0.02.tar.gz'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading testing set: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "data_root= './' # Download the data here\n",
    "\n",
    "cfg.data_root = to_absolute_path(cfg.data_root) # convert relative path to absolute path\n",
    "\n",
    "batch_size = cfg.batch_size\n",
    "\n",
    "trainset = SPEECHCOMMANDS_12C(root=data_root,\n",
    "                              'speech_commands_v0.02') # set up/download train set\n",
    "validset = SPEECHCOMMANDS_12C(**cfg.dataset.val)\n",
    "testset = SPEECHCOMMANDS_12C(**cfg.dataset.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f3bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2135a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # for class weighting, rebalancing silence(10th class) and unknown(11th class) in training set\n",
    "    class_weights = [1,1,1,1,1,1,1,1,1,1,4.6,1/17]\n",
    "    sample_weights = [0] * len(trainset)\n",
    "    #create a list as per length of trainset\n",
    "\n",
    "    for idx, (data,rate,label,speaker_id, _) in enumerate(trainset):\n",
    "        class_weight = class_weights[label]\n",
    "        sample_weights[idx] = class_weight\n",
    "    #apply sample_weights in each data base on their label class in class_weight\n",
    "    #ref: https://www.youtube.com/watch?v=4JFVhJyTZ44&t=518s\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights),replacement=True)\n",
    "            \n",
    "        \n",
    "    trainloader = DataLoader(trainset,                                \n",
    "                                  collate_fn=lambda x: data_processing(x),\n",
    "                                             **cfg.dataloader.train,sampler=sampler)\n",
    "\n",
    "    validloader = DataLoader(validset,                               \n",
    "                                  collate_fn=lambda x: data_processing(x),\n",
    "                                             **cfg.dataloader.val)\n",
    "    \n",
    "    testloader = DataLoader(testset,   \n",
    "                                  collate_fn=lambda x: data_processing(x),\n",
    "                                            **cfg.dataloader.test)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36bc84b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BCResNet_nnAudio'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model.model_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf02e55",
   "metadata": {},
   "source": [
    "# Set up model\n",
    "\n",
    "# Put the model code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07cdec5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT kernels created, time used = 0.1901 seconds\n",
      "STFT filter created, time used = 0.0049 seconds\n",
      "Mel filter created, time used = 0.0049 seconds\n",
      "<class 'models.nnAudio_model.BCResNet_nnAudio'>\n"
     ]
    }
   ],
   "source": [
    "cfg.model.args.input_dim = cfg.model.spec_args.n_mels *101 \n",
    "train_setting=cfg.model.spec_args.trainable_mel\n",
    "n_mel=cfg.model.spec_args.n_mels\n",
    "stft = cfg.model.spec_args.trainable_STFT\n",
    "\n",
    "# nnAudio is integrated into the model at line 50 of models/nnAudio_model.py \n",
    "net = getattr(Model, cfg.model.model_type)(cfg.model)\n",
    "\n",
    "print(type(net))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d01b8a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2cf34eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "   | Name      | Type             | Params\n",
      "------------------------------------------------\n",
      "0  | conv1     | Conv2d           | 416   \n",
      "1  | block1_1  | TransitionBlock  | 352   \n",
      "2  | block1_2  | BroadcastedBlock | 208   \n",
      "3  | block2_1  | TransitionBlock  | 480   \n",
      "4  | block2_2  | BroadcastedBlock | 360   \n",
      "5  | block3_1  | TransitionBlock  | 768   \n",
      "6  | block3_2  | BroadcastedBlock | 544   \n",
      "7  | block3_3  | BroadcastedBlock | 544   \n",
      "8  | block3_4  | BroadcastedBlock | 544   \n",
      "9  | block4_1  | TransitionBlock  | 1.1 K \n",
      "10 | block4_2  | BroadcastedBlock | 760   \n",
      "11 | block4_3  | BroadcastedBlock | 760   \n",
      "12 | block4_4  | BroadcastedBlock | 760   \n",
      "13 | conv2     | Conv2d           | 520   \n",
      "14 | conv3     | Conv2d           | 640   \n",
      "15 | conv4     | Conv2d           | 384   \n",
      "16 | mel_layer | MelSpectrogram   | 9.6 K \n",
      "17 | criterion | CrossEntropyLoss | 0     \n",
      "------------------------------------------------\n",
      "18.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.8 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|                          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  89%|████████▉ | 856/958 [00:50<00:06, 16.81it/s, loss=1.92, v_num=1]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                     | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 858/958 [00:52<00:06, 16.26it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 863/958 [00:52<00:05, 16.32it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 871/958 [00:52<00:05, 16.44it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 879/958 [00:53<00:04, 16.56it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 887/958 [00:53<00:04, 16.68it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 895/958 [00:53<00:03, 16.80it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 903/958 [00:53<00:03, 16.91it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 911/958 [00:53<00:02, 17.03it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 920/958 [00:53<00:02, 17.16it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 929/958 [00:53<00:01, 17.30it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 938/958 [00:53<00:01, 17.43it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 947/958 [00:53<00:00, 17.56it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 956/958 [00:54<00:00, 17.68it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 1: 100%|██████████| 958/958 [00:55<00:00, 17.39it/s, loss=1.92, v_num=1]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 856/958 [00:51<00:06, 16.67it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                     | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                            | 1/102 [00:01<02:55,  1.74s/it]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 864/958 [00:53<00:05, 16.23it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 873/958 [00:53<00:05, 16.36it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 882/958 [00:53<00:04, 16.50it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 891/958 [00:53<00:04, 16.63it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 900/958 [00:53<00:03, 16.77it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 909/958 [00:53<00:02, 16.90it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 918/958 [00:53<00:02, 17.03it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 927/958 [00:54<00:01, 17.16it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 936/958 [00:54<00:01, 17.29it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 945/958 [00:54<00:00, 17.42it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 954/958 [00:54<00:00, 17.55it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Epoch 3: 100%|██████████| 958/958 [00:55<00:00, 17.28it/s, loss=1.39, v_num=1]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 856/958 [00:50<00:06, 16.85it/s, loss=1.16, v_num=1]\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                     | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|▎                            | 1/102 [00:01<02:18,  1.37s/it]\u001b[A\n",
      "Validating:   2%|▌                            | 2/102 [00:01<01:03,  1.57it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 864/958 [00:52<00:05, 16.45it/s, loss=1.16, v_num=1]\u001b[A\n",
      "Validating:   8%|██▎                          | 8/102 [00:01<00:11,  8.02it/s]\u001b[A\n",
      "Validating:  11%|███                         | 11/102 [00:01<00:07, 11.41it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 873/958 [00:52<00:05, 16.53it/s, loss=1.16, v_num=1]\u001b[A\n",
      "Validating:  17%|████▋                       | 17/102 [00:02<00:04, 17.74it/s]\u001b[A\n",
      "Validating:  20%|█████▍                      | 20/102 [00:02<00:04, 19.80it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 882/958 [00:53<00:04, 16.58it/s, loss=1.16, v_num=1]\u001b[A\n",
      "Validating:  25%|███████▏                    | 26/102 [00:02<00:03, 20.96it/s]\u001b[A\n",
      "Validating:  29%|████████▏                   | 30/102 [00:02<00:02, 24.60it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 891/958 [00:53<00:04, 16.65it/s, loss=1.16, v_num=1]\u001b[A\n",
      "Validating:  36%|██████████▏                 | 37/102 [00:02<00:02, 25.61it/s]\u001b[A\n",
      "Validating:  39%|██████████▉                 | 40/102 [00:02<00:02, 26.64it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 900/958 [00:53<00:03, 16.72it/s, loss=1.16, v_num=1]\u001b[A\n",
      "Validating:  45%|████████████▋               | 46/102 [00:03<00:02, 25.40it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 909/958 [00:54<00:02, 16.78it/s, loss=1.16, v_num=1]\u001b[A\n",
      "Validating:  52%|██████████████▌             | 53/102 [00:03<00:01, 26.50it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 918/958 [00:54<00:02, 16.88it/s, loss=1.16, v_num=1]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 927/958 [00:54<00:01, 17.01it/s, loss=1.16, v_num=1]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 936/958 [00:54<00:01, 17.14it/s, loss=1.16, v_num=1]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 945/958 [00:54<00:00, 17.27it/s, loss=1.16, v_num=1]\u001b[A\n",
      "Validating:  88%|████████████████████████▋   | 90/102 [00:03<00:00, 65.83it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 958/958 [00:55<00:00, 17.21it/s, loss=1.16, v_num=1]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 816/856 [00:49<00:02, 16.38it/s, loss=1.02, v_num=1]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "Total length of `Dataloader` across ranks is zero. Please make sure that it returns at least 1 batch.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcfg\u001b[38;5;241m.\u001b[39mtrainer, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n\u001b[1;32m      9\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(net, trainloader, validloader)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:911\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule, test_dataloaders)\u001b[0m\n\u001b[1;32m    906\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use `trainer.test(dataloaders)` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    909\u001b[0m     )\n\u001b[1;32m    910\u001b[0m     dataloaders \u001b[38;5;241m=\u001b[39m test_dataloaders\n\u001b[0;32m--> 911\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:685\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;124;03mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;124;03mas all errors should funnel through them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;124;03m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:954\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtested_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    950\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    951\u001b[0m )\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run test\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtested_ckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1199\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;66;03m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[39;00m\n\u001b[0;32m-> 1199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_dispatch()\n",
      "File \u001b[0;32m~/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1275\u001b[0m, in \u001b[0;36mTrainer._dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dispatch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluating:\n\u001b[0;32m-> 1275\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_type_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_evaluating\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1277\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_type_plugin\u001b[38;5;241m.\u001b[39mstart_predicting(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py:206\u001b[0m, in \u001b[0;36mTrainingTypePlugin.start_evaluating\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_evaluating\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# double dispatch to initiate the test loop\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1286\u001b[0m, in \u001b[0;36mTrainer.run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__setup_profiler()\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluating:\n\u001b[0;32m-> 1286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n",
      "File \u001b[0;32m~/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1328\u001b[0m, in \u001b[0;36mTrainer._run_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluating\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;66;03m# reload dataloaders\u001b[39;00m\n\u001b[0;32m-> 1328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reload_evaluation_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;66;03m# reset trainer on this loop and all child loops in case user connected a custom loop\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:168\u001b[0m, in \u001b[0;36mEvaluationLoop._reload_evaluation_dataloaders\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\"Reloads dataloaders if necessary.\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtesting:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_test_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mval_dataloaders \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_should_reload_val_dl:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mreset_val_dataloader()\n",
      "File \u001b[0;32m~/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:564\u001b[0m, in \u001b[0;36mTrainerDataLoadingMixin.reset_test_dataloader\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    562\u001b[0m has_step \u001b[38;5;241m=\u001b[39m is_overridden(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, pl_module)\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mis_defined() \u001b[38;5;129;01mand\u001b[39;00m has_step:\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_test_batches, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataloaders \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset_eval_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mRunningStage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTESTING\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpl_module\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:504\u001b[0m, in \u001b[0;36mTrainerDataLoadingMixin._reset_eval_dataloader\u001b[0;34m(self, mode, model)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataloaders) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloaders):\n\u001b[1;32m    502\u001b[0m         orig_num_batches \u001b[38;5;241m=\u001b[39m num_batches \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    503\u001b[0m             \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[0;32m--> 504\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhas_len_all_ranks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_type_plugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m         )\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_check(dataloader, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;241m.\u001b[39mdataloader_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_dataloader \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;66;03m# percent or num_steps\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/paper3810/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:118\u001b[0m, in \u001b[0;36mhas_len_all_ranks\u001b[0;34m(dataloader, training_type, model)\u001b[0m\n\u001b[1;32m    115\u001b[0m local_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_length \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal length of `Dataloader` across ranks is zero. Please make sure that it returns at least 1 batch.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_length \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m local_length \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mallow_zero_length_dataloader_with_multiple_devices:\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: Total length of `Dataloader` across ranks is zero. Please make sure that it returns at least 1 batch."
     ]
    }
   ],
   "source": [
    "   \n",
    "    \n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    checkpoint_callback = ModelCheckpoint(**cfg.checkpoint,\n",
    "                                          auto_insert_metric_name=False) #save checkpoint\n",
    "    \n",
    "    callbacks = [checkpoint_callback, lr_monitor]\n",
    "\n",
    "    trainer = Trainer(**cfg.trainer, callbacks=callbacks)\n",
    "    \n",
    "    trainer.fit(net, trainloader, validloader)\n",
    "    trainer.test(net, testloader)\n",
    "    #added validloader, in order to reach validation_step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfa33c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper3810",
   "language": "python",
   "name": "paper3810"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
