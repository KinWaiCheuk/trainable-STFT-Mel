{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac60b08",
   "metadata": {},
   "source": [
    "# Part 1: Training a Linear model with trainable Mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b48aa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/nnAudio/Spectrogram.py:4: Warning: importing Spectrogram subpackage will be deprecated soon. You should import the feature extractor from the feature subpackage. See actual documentation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Libraries related to PyTorch\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torchaudio \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import WeightedRandomSampler,DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Libraries related to PyTorch Lightning\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "\n",
    "# Libraries related to hydra\n",
    "import hydra\n",
    "from hydra.utils import to_absolute_path\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# custom packages\n",
    "from dataset.speechcommands import SPEECHCOMMANDS_12C #for 12 classes KWS task\n",
    "import models as Model \n",
    "from dataloading_util import data_processing\n",
    "\n",
    "#use in ligthning module\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from dataset.speechcommands import idx2name, name2idx\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "# \n",
    "from nnAudio.features.mel import MelSpectrogram, STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed9bc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hydra.initialize(\"conf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda8bc20",
   "metadata": {},
   "source": [
    "# Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e5941d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STFT kernels created, time used = 0.0226 seconds\n",
      "STFT filter created, time used = 0.0023 seconds\n",
      "Mel filter created, time used = 0.0024 seconds\n"
     ]
    }
   ],
   "source": [
    "# model_type= 'BCResNet_nnAudio'\n",
    "device = 'cuda:0'\n",
    "gpus = 1\n",
    "max_epochs = 2\n",
    "check_val_every_n_epoch = 2\n",
    "num_sanity_val_steps = 5\n",
    "data_root= './' # Download the data here\n",
    "download_option= False\n",
    "\n",
    "n_mels= 40\n",
    "mel_layer = MelSpectrogram(sr=16000, \n",
    "                           n_fft=480,\n",
    "                           win_length=None,\n",
    "                           n_mels=n_mels, \n",
    "                           hop_length=160,\n",
    "                           window='hann',\n",
    "                           center=True,\n",
    "                           pad_mode='reflect',\n",
    "                           power=2.0,\n",
    "                           htk=False,\n",
    "                           fmin=0.0,\n",
    "                           fmax=None,\n",
    "                           norm=1,\n",
    "                           trainable_mel=False,\n",
    "                           trainable_STFT=False,\n",
    "                           verbose=True)\n",
    "\n",
    "input_dim= (n_mels*101)\n",
    "output_dim= 12\n",
    "    \n",
    "random_mel= False    \n",
    "batch_size= 100\n",
    "    \n",
    "# cfg.data_root = to_absolute_path(cfg.data_root) # convert relative path to absolute path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ab9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set mel trainable, put \"model.spec_args.trainable_mel=True\" into the overrides list\n",
    "# This is equalivant nnAudio.features.mel.MelSpectrogram(trainable_mel=True) at line 50 of models/nnAudio_model.py \n",
    "\n",
    "# To set mel trainable xxx\n",
    "# To both trainable xxx\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3789b5b7",
   "metadata": {},
   "source": [
    "# Setting up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33040bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basename='speech_commands_v0.02.tar.gz'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading training set: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84843/84843 [00:25<00:00, 3294.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basename='speech_commands_v0.02.tar.gz'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading validation set: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9981/9981 [00:02<00:00, 3328.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basename='speech_commands_test_set_v0.02.tar.gz'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading testing set: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4890/4890 [00:01<00:00, 3503.09it/s]\n"
     ]
    }
   ],
   "source": [
    "trainset = SPEECHCOMMANDS_12C(root=data_root,\n",
    "                              url='speech_commands_v0.02',\n",
    "                              folder_in_archive='SpeechCommands',\n",
    "                              download= download_option,subset= 'training') # set up/download train set\n",
    "\n",
    "validset = SPEECHCOMMANDS_12C(root=data_root,\n",
    "                              url='speech_commands_v0.02',\n",
    "                              folder_in_archive='SpeechCommands',\n",
    "                              download= download_option,subset= 'validation')\n",
    "\n",
    "testset = SPEECHCOMMANDS_12C(root=data_root,\n",
    "                              url='speech_commands_v0.02',\n",
    "                              folder_in_archive='SpeechCommands',\n",
    "                              download= download_option,subset= 'testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c284e8e5",
   "metadata": {},
   "source": [
    "# Data rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2135a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for class weighting, rebalancing silence(10th class) and unknown(11th class) in training set\n",
    "class_weights = [1,1,1,1,1,1,1,1,1,1,4.6,1/17]\n",
    "sample_weights = [0] * len(trainset)\n",
    "#create a list as per length of trainset\n",
    "\n",
    "for idx, (data,rate,label,speaker_id, _) in enumerate(trainset):\n",
    "    class_weight = class_weights[label]\n",
    "    sample_weights[idx] = class_weight\n",
    "#apply sample_weights in each data base on their label class in class_weight\n",
    "#ref: https://www.youtube.com/watch?v=4JFVhJyTZ44&t=518s\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights),replacement=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd65a8",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9a060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset,                                \n",
    "                              collate_fn=lambda x: data_processing(x),\n",
    "                                         batch_size=batch_size,sampler=sampler)\n",
    "\n",
    "validloader = DataLoader(validset,                               \n",
    "                              collate_fn=lambda x: data_processing(x),\n",
    "                                         batch_size=batch_size)\n",
    "\n",
    "testloader = DataLoader(testset,   \n",
    "                              collate_fn=lambda x: data_processing(x),\n",
    "                                        batch_size=batch_size)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203f680",
   "metadata": {},
   "source": [
    "# Ligthning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "906b0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechCommand(LightningModule):\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs, spec = self(batch['waveforms']) \n",
    "        #return outputs [2D] for calculate loss, return spec [3D] for visual\n",
    "        loss = self.criterion(outputs, batch['labels'].long())\n",
    "\n",
    "        acc = sum(outputs.argmax(-1) == batch['labels'])/outputs.shape[0] #batch wise\n",
    "        \n",
    "        self.log('Train/acc', acc, on_step=False, on_epoch=True)\n",
    "        if batch_idx == 0:\n",
    "            self.log_images(spec, 'Train/Spec')\n",
    "            cm = plot_confusion_matrix(batch['labels'].cpu(),\n",
    "                                       outputs.argmax(-1).cpu(),\n",
    "                                       name2idx.keys(),\n",
    "                                       title='Train: Confusion matrix',\n",
    "                                       normalize=False)\n",
    "            self.logger.experiment.add_figure('Train/confusion_maxtrix', cm, global_step=self.current_epoch)            \n",
    "        self.log('Train/Loss', loss, on_step=False, on_epoch=True)\n",
    "        #log(graph title, take acc as data, on_step: plot every step, on_epch: plot every epoch)\n",
    "        return loss\n",
    "\n",
    "     \n",
    "    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx,\n",
    "                       optimizer_closure, on_tpu, using_native_amp, using_lbfgs):\n",
    "        \n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "        with torch.no_grad():\n",
    "            torch.clamp_(self.mel_layer.mel_basis, 0, 1)\n",
    "        #after optimizer step, do clamp function on mel_basis (only applicable for nnAudio)\n",
    "        #FastAudio internal has clamp function\n",
    "        \n",
    "   \n",
    "    def validation_step(self, batch, batch_idx):               \n",
    "        outputs, spec = self(batch['waveforms'])\n",
    "        loss = self.criterion(outputs, batch['labels'].long())        \n",
    "       \n",
    "        self.log('Validation/Loss', loss, on_step=False, on_epoch=True)          \n",
    "\n",
    "        if batch_idx == 0:\n",
    "            fig, axes = plt.subplots(1,1)            \n",
    "            mel_filter_banks = self.mel_layer.mel_basis\n",
    "            for i in mel_filter_banks:\n",
    "                axes.plot(i.cpu())\n",
    "\n",
    "            self.logger.experiment.add_figure(\n",
    "                'Validation/MelFilterBanks',\n",
    "                fig,\n",
    "                global_step=self.current_epoch)\n",
    "                \n",
    "        #these is for plot mel filter band in nnAudio \n",
    "        #fbank_matrix contain all FastAudio filterbank value (mel bases)\n",
    "        \n",
    "        if batch_idx == 0:           \n",
    "            fig, axes = plt.subplots(2,2)\n",
    "            for ax, kernel_num in zip(axes.flatten(), [2,10,20,50]):\n",
    "                ax.plot(self.mel_layer.stft.wsin[kernel_num,0].cpu())  #STFT in included in Melspectrogram()\n",
    "                ax.set_ylim(-1,1)\n",
    "                fig.suptitle('sin')\n",
    "\n",
    "            self.logger.experiment.add_figure(\n",
    "                    'Validation/sin',\n",
    "                    fig,\n",
    "                    global_step=self.current_epoch)\n",
    "\n",
    "            fig, axes = plt.subplots(2,2)\n",
    "            for ax, kernel_num in zip(axes.flatten(), [2,10,20,50]):\n",
    "                ax.plot(self.mel_layer.stft.wcos[kernel_num,0].cpu())\n",
    "                ax.set_ylim(-1,1)\n",
    "                fig.suptitle('cos')\n",
    "\n",
    "            self.logger.experiment.add_figure(\n",
    "                    'Validation/cos',\n",
    "                    fig,\n",
    "                    global_step=self.current_epoch)\n",
    "\n",
    "        self.log_images(spec, 'Validation/Spec')\n",
    "        #plot log_images for 1st epoch_1st batch\n",
    "        \n",
    "            \n",
    "        output_dict = {'outputs': outputs,\n",
    "                       'labels': batch['labels']}        \n",
    "        return output_dict\n",
    "\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        pred = []\n",
    "        label = []\n",
    "        for output in outputs:\n",
    "            pred.append(output['outputs'])\n",
    "            label.append(output['labels'])\n",
    "        label = torch.cat(label, 0)\n",
    "        pred = torch.cat(pred, 0)\n",
    "        acc = sum(pred.argmax(-1) == label)/label.shape[0]\n",
    "        \n",
    "        cm = plot_confusion_matrix(label.cpu(),\n",
    "                                   pred.argmax(-1).cpu(),\n",
    "                                   name2idx.keys(),\n",
    "                                   title='Validation: Confusion matrix',\n",
    "                                   normalize=False)\n",
    "        self.logger.experiment.add_figure('Validation/confusion_maxtrix', cm, global_step=self.current_epoch)\n",
    "        \n",
    "        self.log('Validation/acc', acc, on_step=False, on_epoch=True)    \n",
    "        #use the return value from validation_step: output_dict , to calculate the overall accuracy   \n",
    "        #epoch wise \n",
    "                              \n",
    "    def test_step(self, batch, batch_idx):               \n",
    "        outputs, spec = self(batch['waveforms'])\n",
    "        loss = self.criterion(outputs, batch['labels'].long())        \n",
    "\n",
    "        self.log('Test/Loss', loss, on_step=False, on_epoch=True)          \n",
    "\n",
    "        if batch_idx == 0:\n",
    "            fig, axes = plt.subplots(1,1)\n",
    "            \n",
    "            if self.fastaudio_filter!=None:\n",
    "                fbank_matrix = self.fastaudio_filter.get_fbanks()\n",
    "                f_central = self.fastaudio_filter.f_central\n",
    "                band = self.fastaudio_filter.band\n",
    "                debug_dict = {'fbank_matrix': fbank_matrix,\n",
    "                              'f_central': f_central,\n",
    "                              'band': band}\n",
    "                \n",
    "                for idx, i in enumerate(fbank_matrix.t().detach().cpu().numpy()):\n",
    "                    axes.plot(i)\n",
    "                self.logger.experiment.add_figure(\n",
    "                    'Test/fastaudio_MelFilterBanks',\n",
    "                    fig,\n",
    "                    global_step=self.current_epoch)\n",
    "                \n",
    "            elif self.fastaudio_filter==None:\n",
    "            \n",
    "                mel_filter_banks = self.mel_layer.mel_basis\n",
    "                for i in mel_filter_banks:\n",
    "                    axes.plot(i.cpu())\n",
    "\n",
    "                self.logger.experiment.add_figure(\n",
    "                    'Test/MelFilterBanks',\n",
    "                    fig,\n",
    "                    global_step=self.current_epoch)\n",
    "                \n",
    "        #for plotting mel bases in nnAudio \n",
    "        #fbank_matrix contain all FastAudio filterbank value (mel bases)\n",
    "            \n",
    "            self.log_images(spec, 'Test/Spec')\n",
    "        #plot log_images for 1st epoch_1st batch\n",
    "        \n",
    "        output_dict = {'outputs': outputs,\n",
    "                       'labels': batch['labels']}        \n",
    "        return output_dict\n",
    "\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        pred = []\n",
    "        label = []\n",
    "        for output in outputs:\n",
    "            pred.append(output['outputs'])\n",
    "            label.append(output['labels'])\n",
    "        label = torch.cat(label, 0)\n",
    "        pred = torch.cat(pred, 0)\n",
    "        \n",
    "        result_dict = {}\n",
    "        for key in [None, 'micro', 'macro', 'weighted']:\n",
    "            result_dict[key] = {}\n",
    "            p, r, f1, _ = precision_recall_fscore_support(label.cpu(), pred.argmax(-1).cpu(), average=key, zero_division=0)\n",
    "            result_dict[key]['precision'] = p\n",
    "            result_dict[key]['recall'] = r\n",
    "            result_dict[key]['f1'] = f1\n",
    "            \n",
    "        barplot(result_dict, 'precision')\n",
    "        barplot(result_dict, 'recall')\n",
    "        barplot(result_dict, 'f1')\n",
    "            \n",
    "        acc = sum(pred.argmax(-1) == label)/label.shape[0]\n",
    "        self.log('Test/acc', acc, on_step=False, on_epoch=True)\n",
    "        \n",
    "        self.log('Test/micro_f1', result_dict['micro']['f1'], on_step=False, on_epoch=True)\n",
    "        self.log('Test/macro_f1', result_dict['macro']['f1'], on_step=False, on_epoch=True)\n",
    "        self.log('Test/weighted_f1', result_dict['weighted']['f1'], on_step=False, on_epoch=True)\n",
    "        \n",
    "        cm = plot_confusion_matrix(label.cpu(),\n",
    "                                   pred.argmax(-1).cpu(),\n",
    "                                   name2idx.keys(),\n",
    "                                   title='Test: Confusion matrix',\n",
    "                                   normalize=False)\n",
    "        self.logger.experiment.add_figure('Test/confusion_maxtrix', cm, global_step=self.current_epoch)        \n",
    "        \n",
    "        torch.save(result_dict, \"result_dict.pt\")        \n",
    "        \n",
    "        return result_dict\n",
    "        \n",
    "    def log_images(self, tensors, key):\n",
    "        fig, axes = plt.subplots(2,2, figsize=(12,5), dpi=100)\n",
    "        for ax, tensor in zip(axes.flatten(), tensors):\n",
    "            ax.imshow(tensor.cpu().detach(), aspect='auto', origin='lower', cmap='jet')\n",
    "        plt.tight_layout()\n",
    "        self.logger.experiment.add_figure(f\"{key}\", fig, global_step=self.current_epoch)\n",
    "        plt.close(fig)\n",
    "        #plot images in TensorBoard        \n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        model_param = []\n",
    "        for name, params in self.named_parameters():\n",
    "            if 'mel_layer.' in name:\n",
    "                pass\n",
    "            else:\n",
    "                model_param.append(params)          \n",
    "        optimizer = optim.SGD([\n",
    "                                {\"params\": self.mel_layer.parameters(),\n",
    "                                 \"lr\": 1e-3,\n",
    "                                 \"momentum\": 0.9,\n",
    "                                 \"weight_decay\": 0.001},\n",
    "                                {\"params\": model_param,\n",
    "                                 \"lr\": 1e-3,\n",
    "                                 \"momentum\": 0.9,\n",
    "                                 \"weight_decay\": 0.001}            \n",
    "                              ])\n",
    "        #for applying diff lr in model and mel bases function       \n",
    "\n",
    "\n",
    "def barplot(result_dict, title, figsize=(4,12), minor_interval=0.2, log=False):\n",
    "    fig, ax = plt.subplots(1,1, figsize=figsize)\n",
    "    metric = {}\n",
    "    for idx, item in enumerate(result_dict[None][title]):\n",
    "        metric[idx2name[idx]] = item\n",
    "    xlabels = list(metric.keys())\n",
    "    values = list(metric.values())\n",
    "    if log:\n",
    "        values = np.log(values)\n",
    "    ax.barh(xlabels, values)\n",
    "    ax.tick_params(labeltop=True, labelright=False)\n",
    "    ax.xaxis.grid(True, which='minor')\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(minor_interval))\n",
    "    ax.set_ylim([-1,len(xlabels)])\n",
    "    ax.set_title(title)\n",
    "    ax.grid(axis='x')\n",
    "    ax.grid(b=True, which='minor', linestyle='--')\n",
    "    fig.savefig(f'{title}.png', bbox_inches='tight')\n",
    "    fig.tight_layout() # prevent edge from missing\n",
    "#         fig.set_tight_layout(True)\n",
    "    return fig\n",
    "          \n",
    "    \n",
    "def plot_confusion_matrix(correct_labels,\n",
    "                          predict_labels,\n",
    "                          labels,\n",
    "                          title='Confusion matrix',\n",
    "                          normalize=False):\n",
    "    ''' \n",
    "    Parameters:\n",
    "        correct_labels                  : These are your true classification categories.\n",
    "        predict_labels                  : These are you predicted classification categories\n",
    "        labels                          : This is a lit of labels which will be used to display the axix labels\n",
    "        title='Confusion matrix'        : Title for your matrix\n",
    "        tensor_name = 'MyFigure/image'  : Name for the output summay tensor\n",
    "\n",
    "    Returns:\n",
    "        summary: TensorFlow summary \n",
    "\n",
    "    Other itema to note:\n",
    "        - Depending on the number of category and the data , you may have to modify the figzie, font sizes etc. \n",
    "        - Currently, some of the ticks dont line up due to rotations.\n",
    "    '''\n",
    "    cm = confusion_matrix(correct_labels, predict_labels, labels=range(len(labels)))\n",
    "    if normalize:\n",
    "        cm = cm.astype('float')*10 / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.nan_to_num(cm, copy=True)\n",
    "        cm = cm.astype('int')\n",
    "\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 7), dpi=160, facecolor='w', edgecolor='k')\n",
    "    im = ax.imshow(cm, cmap='Oranges')\n",
    "\n",
    "    classes = [re.sub(r'([a-z](?=[A-Z])|[A-Z](?=[A-Z][a-z]))', r'\\1 ', x) for x in labels]\n",
    "    #classes = ['\\n'.join(l) for l in classes]\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "\n",
    "    ax.set_xlabel('Predicted', fontsize=7)\n",
    "    ax.set_xticks(tick_marks)\n",
    "    c = ax.set_xticklabels(classes, fontsize=6, rotation=0,  ha='center')\n",
    "    ax.xaxis.set_label_position('bottom')\n",
    "    ax.xaxis.tick_bottom()\n",
    "\n",
    "    ax.set_ylabel('True Label', fontsize=7)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_yticklabels(classes, fontsize=6, va ='center')\n",
    "    ax.yaxis.set_label_position('left')\n",
    "    ax.yaxis.tick_left()\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, format(cm[i, j], 'd') if cm[i,j]!=0 else '.', horizontalalignment=\"center\", fontsize=6, verticalalignment='center', color= \"black\")\n",
    "    fig.set_tight_layout(True)\n",
    "\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf02e55",
   "metadata": {},
   "source": [
    "# Set up model\n",
    "\n",
    "## Put the model code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07cdec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linearmodel_nnAudio(SpeechCommand):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.mel_layer = mel_layer\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.linearlayer = nn.Linear(input_dim, output_dim)\n",
    "        #cfg.model.args.input_dim will be calculated in training script \n",
    "   \n",
    "        if random_mel == True:\n",
    "            nn.init.kaiming_uniform_(self.mel_layer.mel_basis, mode='fan_in')\n",
    "            self.mel_layer.mel_basis.requires_grad = False\n",
    "            torch.relu_(self.mel_layer.mel_basis)\n",
    "            self.mel_layer.mel_basis.requires_grad = True\n",
    "            #for randomly initialize mel bases\n",
    "    \n",
    "    def forward(self, x): \n",
    "        #x: 2D [B, 16000]\n",
    "        spec = self.mel_layer(x)  \n",
    "        #spec: 3D [B, F40, T101]\n",
    "        \n",
    "        spec = torch.log(spec+1e-10)\n",
    "        flatten_spec = torch.flatten(spec, start_dim=1) \n",
    "        #flatten_spec: 2D [B, F*T(40*101)] \n",
    "        #start_dim: flattening start from 1st dimention\n",
    "        \n",
    "        out = self.linearlayer(flatten_spec) \n",
    "        #out: 2D [B,number of class(12)] \n",
    "                               \n",
    "        return out, spec \n",
    "\n",
    "# nnAudio is integrated into the model at line 50 of models/nnAudio_model.py \n",
    "net = Linearmodel_nnAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93fcf55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d01b8a",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2cf34eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/root/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/trainer/optimizers.py:37: UserWarning: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | mel_layer   | MelSpectrogram   | 0     \n",
      "1 | criterion   | CrossEntropyLoss | 0     \n",
      "2 | linearlayer | Linear           | 48.5 K\n",
      "-------------------------------------------------\n",
      "48.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "48.5 K    Total params\n",
      "0.194     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|                                                                                                                                                        | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 856/958 [00:09<00:01, 87.35it/s, loss=11.2, v_num=2]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                                   | 0/102 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 858/958 [00:10<00:01, 78.73it/s, loss=11.2, v_num=2]\u001b[A\n",
      "Validating:   2%|███                                                                                                                                                        | 2/102 [00:01<01:09,  1.45it/s]\u001b[A\n",
      "Validating:   3%|████▌                                                                                                                                                      | 3/102 [00:01<00:56,  1.74it/s]\u001b[A\n",
      "Validating:   4%|██████                                                                                                                                                     | 4/102 [00:02<00:51,  1.92it/s]\u001b[A\n",
      "Validating:   5%|███████▌                                                                                                                                                   | 5/102 [00:02<00:47,  2.04it/s]\u001b[A\n",
      "Validating:   6%|█████████                                                                                                                                                  | 6/102 [00:03<00:45,  2.12it/s]\u001b[A\n",
      "Validating:   7%|██████████▋                                                                                                                                                | 7/102 [00:03<00:43,  2.17it/s]\u001b[A\n",
      "Validating:   8%|████████████▏                                                                                                                                              | 8/102 [00:04<00:42,  2.20it/s]\u001b[A\n",
      "Validating:   9%|█████████████▋                                                                                                                                             | 9/102 [00:04<00:41,  2.23it/s]\u001b[A\n",
      "Validating:  10%|███████████████                                                                                                                                           | 10/102 [00:05<00:41,  2.24it/s]\u001b[A\n",
      "Validating:  11%|████████████████▌                                                                                                                                         | 11/102 [00:05<00:40,  2.25it/s]\u001b[A\n",
      "Epoch 1:  91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 869/958 [00:15<00:01, 55.30it/s, loss=11.2, v_num=2]\u001b[A\n",
      "Validating:  13%|███████████████████▋                                                                                                                                      | 13/102 [00:06<00:39,  2.27it/s]\u001b[A\n",
      "Validating:  14%|█████████████████████▏                                                                                                                                    | 14/102 [00:06<00:38,  2.28it/s]\u001b[A\n",
      "Validating:  15%|██████████████████████▋                                                                                                                                   | 15/102 [00:07<00:46,  1.88it/s]\u001b[A\n",
      "Validating:  16%|████████████████████████▏                                                                                                                                 | 16/102 [00:07<00:43,  1.98it/s]\u001b[A\n",
      "Validating:  17%|█████████████████████████▋                                                                                                                                | 17/102 [00:08<00:41,  2.06it/s]\u001b[A\n",
      "Validating:  18%|███████████████████████████▏                                                                                                                              | 18/102 [00:08<00:39,  2.13it/s]\u001b[A\n",
      "Validating:  19%|████████████████████████████▋                                                                                                                             | 19/102 [00:09<00:38,  2.17it/s]\u001b[A\n",
      "Validating:  20%|██████████████████████████████▏                                                                                                                           | 20/102 [00:09<00:37,  2.21it/s]\u001b[A\n",
      "Validating:  21%|███████████████████████████████▋                                                                                                                          | 21/102 [00:10<00:36,  2.22it/s]\u001b[A\n",
      "Validating:  22%|█████████████████████████████████▏                                                                                                                        | 22/102 [00:10<00:35,  2.24it/s]\u001b[A\n",
      "Epoch 1:  92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 880/958 [00:20<00:01, 42.22it/s, loss=11.2, v_num=2]\u001b[A\n",
      "Validating:  24%|████████████████████████████████████▏                                                                                                                     | 24/102 [00:11<00:34,  2.26it/s]\u001b[A\n",
      "Validating:  25%|█████████████████████████████████████▋                                                                                                                    | 25/102 [00:11<00:33,  2.27it/s]\u001b[A\n",
      "Validating:  25%|███████████████████████████████████████▎                                                                                                                  | 26/102 [00:12<00:33,  2.28it/s]\u001b[A\n",
      "Validating:  26%|████████████████████████████████████████▊                                                                                                                 | 27/102 [00:12<00:32,  2.28it/s]\u001b[A\n",
      "Validating:  27%|██████████████████████████████████████████▎                                                                                                               | 28/102 [00:13<00:32,  2.28it/s]\u001b[A\n",
      "Validating:  28%|███████████████████████████████████████████▊                                                                                                              | 29/102 [00:13<00:31,  2.29it/s]\u001b[A\n",
      "Validating:  29%|█████████████████████████████████████████████▎                                                                                                            | 30/102 [00:14<00:31,  2.29it/s]\u001b[A\n",
      "Validating:  30%|██████████████████████████████████████████████▊                                                                                                           | 31/102 [00:14<00:31,  2.29it/s]\u001b[A\n",
      "Validating:  31%|████████████████████████████████████████████████▎                                                                                                         | 32/102 [00:14<00:30,  2.29it/s]\u001b[A\n",
      "Validating:  32%|█████████████████████████████████████████████████▊                                                                                                        | 33/102 [00:15<00:30,  2.29it/s]\u001b[A\n",
      "Epoch 1:  93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 891/958 [00:25<00:01, 34.74it/s, loss=11.2, v_num=2]\u001b[A\n",
      "Validating:  34%|████████████████████████████████████████████████████▊                                                                                                     | 35/102 [00:16<00:29,  2.29it/s]\u001b[A\n",
      "Validating:  35%|██████████████████████████████████████████████████████▎                                                                                                   | 36/102 [00:17<00:36,  1.79it/s]\u001b[A\n",
      "Validating:  36%|███████████████████████████████████████████████████████▊                                                                                                  | 37/102 [00:17<00:34,  1.91it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  37%|█████████████████████████████████████████████████████████▎                                                                                                | 38/102 [00:17<00:31,  2.01it/s]\u001b[A\n",
      "Validating:  38%|██████████████████████████████████████████████████████████▉                                                                                               | 39/102 [00:18<00:30,  2.09it/s]\u001b[A\n",
      "Validating:  39%|████████████████████████████████████████████████████████████▍                                                                                             | 40/102 [00:18<00:28,  2.15it/s]\u001b[A\n",
      "Validating:  40%|█████████████████████████████████████████████████████████████▉                                                                                            | 41/102 [00:19<00:27,  2.18it/s]\u001b[A\n",
      "Validating:  41%|███████████████████████████████████████████████████████████████▍                                                                                          | 42/102 [00:19<00:27,  2.21it/s]\u001b[A\n",
      "Validating:  42%|████████████████████████████████████████████████████████████████▉                                                                                         | 43/102 [00:20<00:26,  2.24it/s]\u001b[A\n",
      "Validating:  43%|██████████████████████████████████████████████████████████████████▍                                                                                       | 44/102 [00:20<00:25,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████        | 902/958 [00:30<00:01, 29.23it/s, loss=11.2, v_num=2]\u001b[A\n",
      "Validating:  45%|█████████████████████████████████████████████████████████████████████▍                                                                                    | 46/102 [00:21<00:24,  2.27it/s]\u001b[A\n",
      "Validating:  46%|██████████████████████████████████████████████████████████████████████▉                                                                                   | 47/102 [00:21<00:24,  2.28it/s]\u001b[A\n",
      "Validating:  47%|████████████████████████████████████████████████████████████████████████▍                                                                                 | 48/102 [00:22<00:23,  2.28it/s]\u001b[A\n",
      "Validating:  48%|█████████████████████████████████████████████████████████████████████████▉                                                                                | 49/102 [00:22<00:23,  2.29it/s]\u001b[A\n",
      "Validating:  49%|███████████████████████████████████████████████████████████████████████████▍                                                                              | 50/102 [00:23<00:22,  2.28it/s]\u001b[A\n",
      "Validating:  50%|█████████████████████████████████████████████████████████████████████████████                                                                             | 51/102 [00:23<00:22,  2.28it/s]\u001b[A\n",
      "Validating:  51%|██████████████████████████████████████████████████████████████████████████████▌                                                                           | 52/102 [00:24<00:21,  2.29it/s]\u001b[A\n",
      "Validating:  52%|████████████████████████████████████████████████████████████████████████████████                                                                          | 53/102 [00:24<00:21,  2.29it/s]\u001b[A\n",
      "Validating:  53%|█████████████████████████████████████████████████████████████████████████████████▌                                                                        | 54/102 [00:24<00:20,  2.29it/s]\u001b[A\n",
      "Validating:  54%|███████████████████████████████████████████████████████████████████████████████████                                                                       | 55/102 [00:25<00:20,  2.29it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 913/958 [00:35<00:01, 25.60it/s, loss=11.2, v_num=2]\u001b[A\n",
      "Validating:  56%|██████████████████████████████████████████████████████████████████████████████████████                                                                    | 57/102 [00:26<00:19,  2.28it/s]\u001b[A\n",
      "Validating:  57%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 58/102 [00:26<00:19,  2.28it/s]\u001b[A\n",
      "Validating:  58%|█████████████████████████████████████████████████████████████████████████████████████████                                                                 | 59/102 [00:27<00:18,  2.29it/s]\u001b[A\n",
      "Validating:  59%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 60/102 [00:27<00:18,  2.30it/s]\u001b[A\n",
      "Validating:  60%|████████████████████████████████████████████████████████████████████████████████████████████                                                              | 61/102 [00:28<00:17,  2.31it/s]\u001b[A\n",
      "Validating:  61%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 62/102 [00:28<00:23,  1.68it/s]\u001b[A\n",
      "Validating:  62%|███████████████████████████████████████████████████████████████████████████████████████████████                                                           | 63/102 [00:29<00:21,  1.82it/s]\u001b[A\n",
      "Validating:  63%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 64/102 [00:29<00:19,  1.95it/s]\u001b[A\n",
      "Validating:  64%|██████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 65/102 [00:30<00:18,  2.03it/s]\u001b[A\n",
      "Validating:  65%|███████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 66/102 [00:30<00:17,  2.11it/s]\u001b[A\n",
      "Epoch 1:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏    | 924/958 [00:40<00:01, 22.54it/s, loss=11.2, v_num=2]\u001b[A\n",
      "Validating:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 68/102 [00:31<00:15,  2.19it/s]\u001b[A\n",
      "Validating:  68%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 69/102 [00:32<00:14,  2.22it/s]\u001b[A\n",
      "Validating:  69%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                | 70/102 [00:32<00:14,  2.24it/s]\u001b[A\n",
      "Validating:  70%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                              | 71/102 [00:32<00:13,  2.26it/s]\u001b[A\n",
      "Validating:  71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                             | 72/102 [00:33<00:13,  2.27it/s]\u001b[A\n",
      "Validating:  72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                           | 73/102 [00:33<00:12,  2.27it/s]\u001b[A\n",
      "Validating:  73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                          | 74/102 [00:34<00:12,  2.28it/s]\u001b[A\n",
      "Validating:  74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                        | 75/102 [00:34<00:11,  2.29it/s]\u001b[A\n",
      "Validating:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 76/102 [00:35<00:11,  2.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating:  75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                     | 77/102 [00:35<00:10,  2.28it/s]\u001b[A\n",
      "Epoch 1:  98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋   | 935/958 [00:45<00:01, 20.41it/s, loss=11.2, v_num=2]\u001b[A\n",
      "Validating:  77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                  | 79/102 [00:36<00:10,  2.28it/s]\u001b[A\n",
      "Validating:  78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                 | 80/102 [00:36<00:09,  2.28it/s]\u001b[A\n",
      "Validating:  79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                               | 81/102 [00:37<00:09,  2.28it/s]\u001b[A\n",
      "Validating:  80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 82/102 [00:37<00:08,  2.29it/s]\u001b[A\n",
      "Validating:  81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 83/102 [00:38<00:08,  2.28it/s]\u001b[A\n",
      "Validating:  82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 84/102 [00:38<00:07,  2.28it/s]\u001b[A\n",
      "Validating:  83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 85/102 [00:39<00:07,  2.28it/s]\u001b[A\n",
      "Validating:  84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 86/102 [00:39<00:06,  2.29it/s]\u001b[A\n",
      "Validating:  85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 87/102 [00:39<00:06,  2.28it/s]\u001b[A\n",
      "Validating:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 88/102 [00:40<00:06,  2.28it/s]\u001b[A\n",
      "Epoch 1:  99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 946/958 [00:50<00:00, 18.69it/s, loss=11.2, v_num=2]\u001b[A\n",
      "Validating:  88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 90/102 [00:41<00:05,  2.28it/s]\u001b[A\n",
      "Validating:  89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 91/102 [00:41<00:04,  2.29it/s]\u001b[A\n",
      "Validating:  90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 92/102 [00:42<00:04,  2.29it/s]\u001b[A\n",
      "Validating:  91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 93/102 [00:42<00:03,  2.29it/s]\u001b[A\n",
      "Validating:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 94/102 [00:43<00:05,  1.57it/s]\u001b[A\n",
      "Validating:  93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 95/102 [00:44<00:04,  1.73it/s]\u001b[A\n",
      "Validating:  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 96/102 [00:44<00:03,  1.87it/s]\u001b[A\n",
      "Validating:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍       | 97/102 [00:44<00:02,  1.98it/s]\u001b[A\n",
      "Validating:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 98/102 [00:45<00:01,  2.06it/s]\u001b[A\n",
      "Validating:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍    | 99/102 [00:45<00:01,  2.12it/s]\u001b[A\n",
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 957/958 [00:56<00:00, 17.06it/s, loss=11.2, v_num=2]\u001b[A\n",
      "Validating:  99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 101/102 [00:46<00:00,  2.21it/s]\u001b[A\n",
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 958/958 [00:57<00:00, 16.61it/s, loss=11.2, v_num=2]\u001b[A\n",
      "                                                                                                                                                                                                            \u001b[A"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Validation/Loss='",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1178/1477870228.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     num_sanity_val_steps=num_sanity_val_steps, callbacks=callbacks)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#added validloader, in order to reach validation_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    738\u001b[0m             )\n\u001b[1;32m    739\u001b[0m             \u001b[0mtrain_dataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         self._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    741\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \"\"\"\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;31m# TODO: ckpt_path only in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_EVALUATE_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# the global step is manually decreased here due to backwards compatibility with existing loggers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36mon_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshould_check_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\u001b[0m in \u001b[0;36m_run_validation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_accumulated_batches_reached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_run_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36mon_run_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_evaluation_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# enable train mode again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36m_on_evaluation_end\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_test_end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_validation_end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# reset the logger connector state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mcall_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m             \u001b[0mcallback_fx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback_fx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m                 \u001b[0mcallback_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m             \u001b[0;31m# next call hook in lightningModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py\u001b[0m in \u001b[0;36mon_validation_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;34m\"\"\"Called when the validation loop ends.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_validation_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36mon_validation_end\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    331\u001b[0m         ):\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.LightningModule\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;31m# here we call each mode sequentially\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;31m# Mode 1: save the top k checkpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_top_k_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Mode 2: save monitor=None checkpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_none_monitor_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m_save_top_k_checkpoint\u001b[0;34m(self, trainer, monitor_candidates)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_monitor_top_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_best_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonitor_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m_update_best_and_save\u001b[0;34m(self, current, trainer, monitor_candidates)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"min\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"-inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_metric_interpolated_filepath_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdel_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;31m# save the current score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m_get_metric_interpolated_filepath_name\u001b[0;34m(self, monitor_candidates, trainer, del_filepath)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor_candidates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_METRIC\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdel_filepath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     ) -> str:\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_checkpoint_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mversion_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTARTING_VERSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36mformat_checkpoint_name\u001b[0;34m(self, metrics, filename, ver)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \"\"\"\n\u001b[1;32m    581\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_checkpoint_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_insert_metric_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_insert_metric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mver\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.8.10/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m_format_checkpoint_name\u001b[0;34m(cls, filename, metrics, prefix, auto_insert_metric_name)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                     \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Validation/Loss='"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 958/958 [01:08<00:00, 14.00it/s, loss=11.2, v_num=2]"
     ]
    }
   ],
   "source": [
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "checkpoint_callback = ModelCheckpoint( monitor= 'Validation/Loss',\n",
    "                                      filename= \"e={epoch=02d}-valid_loss={Validation/Loss=.2f}-valid_acc={Validation/acc=.2f}\",\n",
    "                                      save_top_k= 1,   #only save the one whatever the minimum\n",
    "                                      mode= 'min',     #if validation/acc, then will monitor 'max'\n",
    "                                      save_last= True, #save the last point \n",
    "                                      every_n_epochs= check_val_every_n_epoch,\n",
    "                                      auto_insert_metric_name=False) #save checkpoint\n",
    "\n",
    "callbacks = [checkpoint_callback, lr_monitor]\n",
    "\n",
    "trainer = Trainer(gpus=gpus, max_epochs=max_epochs,\n",
    "    check_val_every_n_epoch= check_val_every_n_epoch,\n",
    "    num_sanity_val_steps=num_sanity_val_steps, callbacks=callbacks)\n",
    "\n",
    "trainer.fit(net, trainloader, validloader)\n",
    "trainer.test(net, testloader)\n",
    "#added validloader, in order to reach validation_step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfa33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f74906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8.10",
   "language": "python",
   "name": "python3.8.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
